{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO32w8SRGzgLJv/HjGmhf3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palaceIA/CICS_Project/blob/main/src/notebooks/albert/albert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning ALBERT v2\n",
        "Esse jupyter faz parte na nossa pesquisa para o Congresso Internacional (CICS) , aqui você ira encontrar nosso experimento referente ao modelo ALBERT e os nossos devidos resultados. O dataset utlizado foi o \"dair-ai/emotion\" disponivel no HuggingFace ."
      ],
      "metadata": {
        "id": "nP76wUB6re-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BASE ALBERT v2\n",
        "Modelo pré-treinado em inglês usando um objetivo de modelagem de linguagem mascarada (MLM). Foi introduzido neste artigo e lançado pela primeira vez neste repositório . Este modelo, como todos os modelos ALBERT, não é caseado: não faz diferença entre inglês e inglês.\n",
        "\n",
        "ALBERT é um modelo de transformadores pré-treinado em um grande corpus de dados em inglês de forma autossupervisionada. Isso significa que ele foi pré-treinado apenas nos textos brutos, sem humanos rotulando-os de forma alguma (é por isso que ele pode usar muitos dados disponíveis publicamente) com um processo automático para gerar entradas e rótulos desses textos. Mais precisamente, ele foi pré-treinado com dois objetivos:\n",
        "\n",
        "Modelagem de linguagem mascarada (MLM): pegando uma frase, o modelo mascara aleatoriamente 15% das palavras na entrada e então executa a frase mascarada inteira através do modelo e tem que prever as palavras mascaradas. Isso é diferente das redes neurais recorrentes tradicionais (RNNs) que geralmente veem as palavras uma após a outra, ou de modelos autorregressivos como GPT que mascaram internamente os tokens futuros. Ele permite que o modelo aprenda uma representação bidirecional da frase.\n",
        "Previsão de ordenação de frases (SOP): ALBERT usa uma perda de pré-treinamento baseada na previsão da ordenação de dois segmentos consecutivos de texto.\n",
        "Dessa forma, o modelo aprende uma representação interna da língua inglesa que pode então ser usada para extrair características úteis para tarefas posteriores: se você tiver um conjunto de dados de frases rotuladas, por exemplo, poderá treinar um classificador padrão usando as características produzidas pelo modelo ALBERT como entradas.\n",
        "\n",
        "ALBERT é particular porque compartilha suas camadas em seu Transformer. Portanto, todas as camadas têm os mesmos pesos. Usar camadas repetidas resulta em uma pequena pegada de memória, no entanto, o custo computacional permanece semelhante a uma arquitetura do tipo BERT com o mesmo número de camadas ocultas, pois tem que iterar pelo mesmo número de camadas (repetidas).\n",
        "\n",
        "Esta é a segunda versão do modelo base. A versão 2 é diferente da versão 1 devido a diferentes taxas de abandono, dados de treinamento adicionais e treinamento mais longo. Ela tem melhores resultados em quase todas as tarefas posteriores.\n",
        "\n",
        "Este modelo tem a seguinte configuração:\n",
        "\n",
        "12 camadas repetidas\n",
        "128 dimensão de incorporação\n",
        "768 dimensão oculta\n",
        "12 cabeças de atenção\n",
        "Parâmetros 11M\n",
        "\n",
        "Você pode usar o modelo bruto para modelagem de linguagem mascarada ou previsão da próxima frase, mas ele é mais destinado a ser ajustado em uma tarefa downstream. Veja o hub do modelo para procurar versões ajustadas em uma tarefa que lhe interesse.\n",
        "\n",
        "Note que este modelo tem como objetivo principal ser ajustado em tarefas que usam a frase inteira (potencialmente mascarada) para tomar decisões, como classificação de sequência, classificação de token ou resposta a perguntas. Para tarefas como geração de texto, você deve olhar para um modelo como GPT2.\n",
        "\n"
      ],
      "metadata": {
        "id": "vI90WrqhrfAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando os modulos\n",
        "!pip install torch transformers datasets matplotlib numpy scikit-learn pandas scipy"
      ],
      "metadata": {
        "id": "c-zwt8wwsB8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando os modulos"
      ],
      "metadata": {
        "id": "wAlOmfZMsH1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    AutoTokenizer,\n",
        "    AutoModel ,\n",
        "    Trainer\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score ,\n",
        "    f1_score ,\n",
        "    classification_report ,\n",
        "    roc_curve ,\n",
        "    auc\n",
        ")\n",
        "from scipy.special import softmax\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "5f43lsxLsB-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando o dataset"
      ],
      "metadata": {
        "id": "DSifnG2gsN40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_data = \"dair-ai/emotion\"\n",
        "dataset = load_dataset(id_data)"
      ],
      "metadata": {
        "id": "YlfeQf1DsCBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entendendo os dados"
      ],
      "metadata": {
        "id": "ug9U-stLsPtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estrutura do dataset\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "mmtTnfiXsCDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de classes do dataset\n",
        "classes = dataset['train'].features['label'].names\n",
        "classes"
      ],
      "metadata": {
        "id": "EmyfiMSzsCHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alterando o formato do dataset para um tipo pandas\n",
        "dataset.set_format(type='pandas')\n",
        "df_pandas = dataset['train'][:]\n",
        "df_pandas.head()"
      ],
      "metadata": {
        "id": "udWUAtS5sCKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma tabela para cada classe correspondente\n",
        "df_pandas['label_name'] = df_pandas['label'].apply(lambda x : classes[x])\n",
        "df_pandas.head()"
      ],
      "metadata": {
        "id": "FkrDA44msCOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o balanceamento das classes\n",
        "total_classes = df_pandas['label_name'].value_counts()\n",
        "total_classes"
      ],
      "metadata": {
        "id": "_ovgxE0NsCRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resetando o formato original dos dados\n",
        "dataset.reset_format()"
      ],
      "metadata": {
        "id": "y3v4e1Q-sCT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando o tokenizador do modelo"
      ],
      "metadata": {
        "id": "c0kPB-dcsisW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_model = 'albert/albert-base-v2'\n",
        "tokenizador = AutoTokenizer.from_pretrained(id_model)"
      ],
      "metadata": {
        "id": "k2hXjXb4sCYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# passaremos a quantidade de batchs dos dados\n",
        "# Para aplicar essas a tokenizaço de todos os dados\n",
        "# basta usar o metodo map()\n",
        "# Função para tokenizar o dataset\n",
        "def tokenizador_lote(batch):\n",
        "    temp = tokenizador(\n",
        "        batch['text'],  # Aqui, 'batch' deve ser um dicionário com uma chave 'text'\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "    )\n",
        "    return temp\n"
      ],
      "metadata": {
        "id": "pgk95rAtsCaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizando dados"
      ],
      "metadata": {
        "id": "siIStAsns0IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_tokenizado = dataset.map(\n",
        "    tokenizador_lote,\n",
        "    batched = True ,\n",
        "    batch_size=None\n",
        ")"
      ],
      "metadata": {
        "id": "kDrgNcJas2Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando modelo"
      ],
      "metadata": {
        "id": "xe0d__xBtO9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= AutoModel.from_pretrained(id_model)"
      ],
      "metadata": {
        "id": "-9z1JmHBtQka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "9sbyE3EztQmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurações iniciais para o ajuste fino"
      ],
      "metadata": {
        "id": "yJpacOwctS7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Armazenando numero de classes\n",
        "numero_classes = len(classes)\n",
        "# Inicializando plataforma CUDA\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    id_model , num_labels = numero_classes\n",
        ")"
      ],
      "metadata": {
        "id": "vov_LRJltYDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "xE_AnvXmtZub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "2QmBeU0Otar5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "tin9khQXtbpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurações do treinamento"
      ],
      "metadata": {
        "id": "xJJch_6xtc9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho do lote\n",
        "batch_size = 15\n",
        "model_name = 'albert-base-v2-emotions'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name ,\n",
        "    num_train_epochs=4 ,\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size= batch_size ,\n",
        "    per_device_eval_batch_size=batch_size ,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy='epoch' ,\n",
        "    disable_tqdm=False\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "mckQiqEdtfS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computação de métricas"
      ],
      "metadata": {
        "id": "hNL10cCBtlBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computer_metrics(pred) :\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels,preds,average='weighted')\n",
        "    acc = accuracy_score(labels,preds)\n",
        "    return {\"acurracy\" : acc , \"f1\" : f1}"
      ],
      "metadata": {
        "id": "uk3uu1SftfZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento"
      ],
      "metadata": {
        "id": "Xt6ZOSg0tp4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model ,\n",
        "    args = training_args ,\n",
        "    compute_metrics = computer_metrics ,\n",
        "    train_dataset = dataset_tokenizado['train'] ,\n",
        "    eval_dataset= dataset_tokenizado['validation'] ,\n",
        "    tokenizer = tokenizador\n",
        ")"
      ],
      "metadata": {
        "id": "6Xxn0f92tfbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "yQ9a_Krptshw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliando modelo"
      ],
      "metadata": {
        "id": "mXqoZEOituMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ouptus = trainer.predict(\n",
        "    dataset_tokenizado['test']\n",
        ")\n",
        "pred_ouptus.metrics"
      ],
      "metadata": {
        "id": "5WHY4j2Ftwjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(\n",
        "    pred_ouptus.predictions,axis=1\n",
        ")\n",
        "y_test = dataset_tokenizado['test'][:]['label']"
      ],
      "metadata": {
        "id": "E_B_FqLItwlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[:5]"
      ],
      "metadata": {
        "id": "XYNKH3s8twng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "id": "syC4Ti15twpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes"
      ],
      "metadata": {
        "id": "V8aLwFbFtwxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=classes))"
      ],
      "metadata": {
        "id": "we4qo0zLt2m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_dict = classification_report(y_test, y_pred, target_names=classes, output_dict=True)\n",
        "report_dict"
      ],
      "metadata": {
        "id": "MUYlDHrDt3mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "report_df = report_df.round(4)"
      ],
      "metadata": {
        "id": "JKHWt8I8t5fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe a tabela\n",
        "print(report_df)"
      ],
      "metadata": {
        "id": "d65cIRISt6uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_multiclass_roc(y_true, y_probs, class_names):\n",
        "    n_classes = len(class_names)\n",
        "    y_true_bin = label_binarize(y_true, classes=list(range(n_classes)))\n",
        "\n",
        "    fpr, tpr, roc_auc = {}, {}, {}\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr[i], tpr[i], lw=2, label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Falso Positivo')\n",
        "    plt.ylabel('Verdadeiro Positivo')\n",
        "    plt.title('Curvas ROC por Emoção')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "f09g1RFXt7u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(dataset_tokenizado['test'])"
      ],
      "metadata": {
        "id": "0T2e81Mnt8ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica softmax sobre os logits\n",
        "y_pred_proba = softmax(pred.predictions, axis=1)"
      ],
      "metadata": {
        "id": "AeroiaD2t-jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_multiclass_roc(y_test, y_pred_proba, classes)"
      ],
      "metadata": {
        "id": "zPQrLCmQt_ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_roc_dataframe(y_true, y_probs, class_names):\n",
        "    n_classes = len(classes)\n",
        "    y_true_bin = label_binarize(y_true, classes=list(range(n_classes)))\n",
        "\n",
        "    dataframes = []\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr, tpr, thresholds = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'class': classes[i],\n",
        "            'fpr': fpr,\n",
        "            'tpr': tpr,\n",
        "            'threshold': thresholds,\n",
        "            'auc': roc_auc  # mesmo valor repetido pra cada linha, pra facilitar agrupamentos\n",
        "        })\n",
        "\n",
        "        dataframes.append(df)\n",
        "\n",
        "    return pd.concat(dataframes, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "x8BzhtfDuB7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_df = get_roc_dataframe(y_test, y_pred_proba,classes)\n",
        "roc_df"
      ],
      "metadata": {
        "id": "GTuodF5wuC2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_df.to_csv(\"curva_roc_por_classe.csv\", index=False)"
      ],
      "metadata": {
        "id": "H-06NaFfuFB6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
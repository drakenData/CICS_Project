{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ3fB8Z/TrI7d45/O0CzQA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palaceIA/CICS_Project/blob/main/src/notebooks/bert-base/bert_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning Bert Base\n",
        "\n",
        "Esse jupyter faz parte na nossa pesquisa para o Congresso Internacional (CICS) , aqui você ira encontrar nosso experimento referente ao modelo Bert Base e os nossos devidos resultados. O dataset utlizado foi o \"dair-ai/emotion\" disponivel no HuggingFace ."
      ],
      "metadata": {
        "id": "JHSSa09e8SoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert-base-uncased\n",
        "\n",
        "BERT é um modelo de transformadores pré-treinado em um grande corpus de dados em inglês de forma autossupervisionada. Isso significa que ele foi pré-treinado apenas nos textos brutos, sem humanos rotulando-os de forma alguma (é por isso que ele pode usar muitos dados disponíveis publicamente) com um processo automático para gerar entradas e rótulos desses textos. Mais precisamente, ele foi pré-treinado com dois objetivos:\n",
        "\n",
        "Modelagem de linguagem mascarada (MLM): pegando uma frase, o modelo mascara aleatoriamente 15% das palavras na entrada e então executa a frase mascarada inteira através do modelo e tem que prever as palavras mascaradas. Isso é diferente das redes neurais recorrentes tradicionais (RNNs) que geralmente veem as palavras uma após a outra, ou de modelos autorregressivos como GPT que mascara internamente os tokens futuros. Ele permite que o modelo aprenda uma representação bidirecional da frase.\n",
        "Previsão da próxima frase (NSP): os modelos concatenam duas frases mascaradas como entradas durante o pré-treinamento. Às vezes, elas correspondem a frases que estavam próximas uma da outra no texto original, às vezes não. O modelo então tem que prever se as duas frases estavam se seguindo ou não.\n",
        "Dessa forma, o modelo aprende uma representação interna da língua inglesa que pode então ser usada para extrair características úteis para tarefas posteriores: se você tiver um conjunto de dados de frases rotuladas, por exemplo, poderá treinar um classificador padrão usando as características produzidas pelo modelo BERT como entradas.\n",
        "\n",
        "Modelo tem como objetivo principal ser ajustado em tarefas que usam a frase inteira (potencialmente mascarada) para tomar decisões, como classificação de sequência, classificação de token ou resposta a perguntas. Para tarefas como geração de texto, você deve olhar para um modelo como GPT2."
      ],
      "metadata": {
        "id": "9oNIl9ji8Uyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento do modelo\n",
        "\n",
        "O modelo BERT foi pré-treinado no BookCorpus , um conjunto de dados composto por 11.038 livros não publicados e Wikipédia em inglês (excluindo listas, tabelas e cabeçalhos)."
      ],
      "metadata": {
        "id": "BczgP_JJ8r5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando os modulos\n",
        "!pip install torch transformers datasets matplotlib numpy scikit-learn pandas"
      ],
      "metadata": {
        "id": "__0FBqzn82Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando os modulos"
      ],
      "metadata": {
        "id": "UNTJFTNf85Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    AutoTokenizer,\n",
        "    AutoModel\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score ,\n",
        "    f1_score ,\n",
        "    classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "dXu6trm589oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o dataset"
      ],
      "metadata": {
        "id": "DB_VHryj8_Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_data = \"dair-ai/emotion\"\n",
        "dataset = load_dataset(id_data)"
      ],
      "metadata": {
        "id": "VovDjEZT9A16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entendendo os dados"
      ],
      "metadata": {
        "id": "kmDIxUdU9DDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estrutura do dataset\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "rE6HFwnU9GPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de classes do dataset\n",
        "classes = dataset['train'].features['label'].names\n",
        "classes"
      ],
      "metadata": {
        "id": "F287-jUj9H9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alterando o formato do dataset para um tipo pandas\n",
        "dataset.set_format(type='pandas')\n",
        "df_pandas = dataset['train'][:]\n",
        "df_pandas.head()"
      ],
      "metadata": {
        "id": "_q1yzGPI9KvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma tabela para cada classe correspondente\n",
        "df_pandas['label_name'] = df_pandas['label'].apply(lambda x : classes[x])\n",
        "df_pandas.head()"
      ],
      "metadata": {
        "id": "NvP_LtlE9MQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o balanceamento das classes\n",
        "total_classes = df_pandas['label_name'].value_counts()\n",
        "total_classes"
      ],
      "metadata": {
        "id": "gTo6Qkdj9OQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resetando o formato original dos dados\n",
        "dataset.reset_format()"
      ],
      "metadata": {
        "id": "IQDx4bes9P4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o tokenizador do modelo"
      ],
      "metadata": {
        "id": "c9pcVocl9RA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_model = 'google-bert/bert-base-uncased'\n",
        "tokenizador = AutoTokenizer.from_pretrained(id_model)"
      ],
      "metadata": {
        "id": "gNpjJXJd9Txk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# passaremos a quantidade de batchs dos dados\n",
        "# Para aplicar essas a tokenizaço de todos os dados\n",
        "# basta usar o metodo map()\n",
        "# Função para tokenizar o dataset\n",
        "def tokenizador_lote(batch):\n",
        "    temp = tokenizador(\n",
        "        batch['text'],  # Aqui, 'batch' deve ser um dicionário com uma chave 'text'\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "    )\n",
        "    return temp\n",
        ""
      ],
      "metadata": {
        "id": "76MaxDUo9ZiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizando os dados"
      ],
      "metadata": {
        "id": "4gVM5UTh9bL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_tokenizado = dataset.map(\n",
        "    tokenizador_lote,\n",
        "    batched = True ,\n",
        "    batch_size=None\n",
        ")"
      ],
      "metadata": {
        "id": "SCsWeFJC9dmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o modelo"
      ],
      "metadata": {
        "id": "RAnWFZG19gUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= AutoModel.from_pretrained(id_model)"
      ],
      "metadata": {
        "id": "ZClfAcy-9fzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "7zUUglEP9qf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurações iniciais para o ajuste fino\n"
      ],
      "metadata": {
        "id": "jEAzzBtm9rat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Armazenando numero de classes\n",
        "numero_classes = len(classes)\n",
        "# Inicializando plataforma CUDA\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    id_model , num_labels = numero_classes\n",
        ")"
      ],
      "metadata": {
        "id": "QjulZH0d9t-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "XFlEnEWc9wBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurações do treinamento"
      ],
      "metadata": {
        "id": "Se3eoM4_9xYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho do lote\n",
        "batch_size = 15\n",
        "model_name = 'bert-base-uncased-emotions'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name ,\n",
        "    num_train_epochs=4 ,\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size= batch_size ,\n",
        "    per_device_eval_batch_size=batch_size ,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy='epoch' ,\n",
        "    disable_tqdm=False\n",
        ")"
      ],
      "metadata": {
        "id": "4TGVOolI906p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computação de métricas"
      ],
      "metadata": {
        "id": "Ze3HhIhC94Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computer_metrics(pred) :\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels,preds,average='weighted')\n",
        "    acc = accuracy_score(labels,preds)\n",
        "    return {\"acurracy : \" : acc , \"f1\" : f1}"
      ],
      "metadata": {
        "id": "KTmw5w4E9-rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento"
      ],
      "metadata": {
        "id": "aZoTHE-U-Axf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model ,\n",
        "    args = training_args ,\n",
        "    compute_metrics = computer_metrics ,\n",
        "    train_dataset = dataset_tokenizer['train'] ,\n",
        "    eval_dataset= dataset_tokenizer['validation'] ,\n",
        "    tokenizer = tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "qimKafhl-CWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Ryo9eXLJ-D6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliando modelo"
      ],
      "metadata": {
        "id": "eHMSSVzO-GpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ouptus = trainer.predict(\n",
        "    dataset_tokenizado['test']\n",
        ")\n",
        "pred_ouptus.metrics"
      ],
      "metadata": {
        "id": "ietTbPq3-Iy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(\n",
        "    pred_ouptus.predictions,axis=1\n",
        ")\n",
        "y_true = dataset_tokenizer['test'][:]['label']"
      ],
      "metadata": {
        "id": "LLZPL9Bt-I0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true,y_preds,output_dict=True))"
      ],
      "metadata": {
        "id": "kb1dstAD-I3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "report_df = report_df.round(4)\n",
        "\n",
        "# Exibe a tabela\n",
        "print(report_df)"
      ],
      "metadata": {
        "id": "gpZuMyuz-I5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binariza os labels para ROC multiclasse\n",
        "y_test_bin = label_binarize(y_true, classes=list(range(len(classes))))\n",
        "\n",
        "# Calcula curva ROC e AUC para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plota as curvas ROC\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(len(classes)):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2,\n",
        "             label=f\"{classes[i]} (AUC = {roc_auc[i]:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
        "plt.ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
        "plt.title(\"Curva ROC por Classe\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WJc_uPR7-I66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for i, cls in enumerate(classes):\n",
        "    # Protege contra índice fora do range se houver poucos thresholds\n",
        "    fpr_value = fpr[i][1] if len(fpr[i]) > 1 else fpr[i][0]\n",
        "    tpr_value = tpr[i][1] if len(tpr[i]) > 1 else tpr[i][0]\n",
        "\n",
        "    data.append({\n",
        "        \"Classe\": cls,\n",
        "        \"AUC\": round(roc_auc[i], 4),\n",
        "        \"FPR (Exemplo)\": round(fpr_value, 4),\n",
        "        \"TPR (Exemplo)\": round(tpr_value, 4)\n",
        "    })\n",
        "\n",
        "roc_df = pd.DataFrame(data)\n",
        "print(roc_df)"
      ],
      "metadata": {
        "id": "MWjx7OOW-RBi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
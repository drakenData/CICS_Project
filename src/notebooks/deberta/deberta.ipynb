{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMggX87Rp/SL3sxYs4yijoG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palaceIA/CICS_Project/blob/main/src/notebooks/deberta/albert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning DeBERTa Base\n",
        "Esse jupyter faz parte na nossa pesquisa para o Congresso Internacional (CICS) , aqui você ira encontrar nosso experimento referente ao modelo DeBERTa Base e os nossos devidos resultados. O dataset utlizado foi o \"dair-ai/emotion\" disponivel no HuggingFace .\n"
      ],
      "metadata": {
        "id": "M6Efr2qV0VjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DeBERTa-base\n",
        "\n",
        "DeBERTa melhora os modelos BERT e RoBERTa usando atenção desemaranhada e decodificador de máscara aprimorado. Ele supera BERT e RoBERTa na maioria das tarefas NLU com 80 GB de dados de treinamento.\n",
        "\n",
        "link : https://github.com/microsoft/DeBERTa"
      ],
      "metadata": {
        "id": "OMKST0ZG0buP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando os modulos\n",
        "!pip install torch transformers datasets matplotlib numpy scikit-learn pandas"
      ],
      "metadata": {
        "id": "B3yBmu7m0of0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando os modulos"
      ],
      "metadata": {
        "id": "Mw0qNtLU0p4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    AutoTokenizer,\n",
        "    AutoModel\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score ,\n",
        "    f1_score ,\n",
        "    classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "e9rbo7XI0szb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o dataset"
      ],
      "metadata": {
        "id": "aEGYlYwS0uOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_data = \"dair-ai/emotion\"\n",
        "dataset = load_dataset(id_data)"
      ],
      "metadata": {
        "id": "BpmpfiJd0w1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entendendo os dados"
      ],
      "metadata": {
        "id": "YmZgO63P0xrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estrutura do dataset\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "RFPugQGD00eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de classes do dataset\n",
        "classes = dataset['train'].features['label'].names\n",
        "classes"
      ],
      "metadata": {
        "id": "Zg66Y0DZ01_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alterando o formato do dataset para um tipo pandas\n",
        "dataset.set_format(type='pandas')\n",
        "df_pandas = dataset['train'][:]\n",
        "df_pandas.head()"
      ],
      "metadata": {
        "id": "yMl5OwBj03NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma tabela para cada classe correspondente\n",
        "df_pandas['label_name'] = df_pandas['label'].apply(lambda x : classes[x])\n",
        "df_pandas.head()"
      ],
      "metadata": {
        "id": "CtCVPlyp04P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o balanceamento das classes\n",
        "total_classes = df_pandas['label_name'].value_counts()\n",
        "total_classes"
      ],
      "metadata": {
        "id": "rdw7gLC705bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resetando o formato original dos dados\n",
        "dataset.reset_format()"
      ],
      "metadata": {
        "id": "hgFeAGvm06th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o tokenizador do modelo"
      ],
      "metadata": {
        "id": "YCsNOrTB07cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_model = 'microsoft/deberta-base'\n",
        "tokenizador = AutoTokenizer.from_pretrained(id_model)"
      ],
      "metadata": {
        "id": "WepiTZXt09jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# passaremos a quantidade de batchs dos dados\n",
        "# Para aplicar essas a tokenizaço de todos os dados\n",
        "# basta usar o metodo map()\n",
        "# Função para tokenizar o dataset\n",
        "def tokenizador_lote(batch):\n",
        "    temp = tokenizador(\n",
        "        batch['text'],  # Aqui, 'batch' deve ser um dicionário com uma chave 'text'\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "    )\n",
        "    return temp\n",
        ""
      ],
      "metadata": {
        "id": "ky5YwBf21E9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizando dados"
      ],
      "metadata": {
        "id": "1-_2ZDOr1F4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_tokenizado = dataset.map(\n",
        "    tokenizador_lote,\n",
        "    batched = True ,\n",
        "    batch_size=None\n",
        ")"
      ],
      "metadata": {
        "id": "7ge1aFpV1H6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando modelo"
      ],
      "metadata": {
        "id": "QJPE54HV1JcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= AutoModel.from_pretrained(id_model)"
      ],
      "metadata": {
        "id": "kYKCXm4X1K5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "-kEWFiIk1K8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurações iniciais para o ajuste fino"
      ],
      "metadata": {
        "id": "e_pEkgDU1NuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Armazenando numero de classes\n",
        "numero_classes = len(classes)\n",
        "# Inicializando plataforma CUDA\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    id_model , num_labels = numero_classes\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "OpeGtn2e1RKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "jnZl9QNK1Vun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurações do treinamento"
      ],
      "metadata": {
        "id": "6ivK6sEb1Sih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho do lote\n",
        "batch_size = 15\n",
        "model_name = 'distilbert-base-uncased-emotions'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name ,\n",
        "    num_train_epochs=4 ,\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size= batch_size ,\n",
        "    per_device_eval_batch_size=batch_size ,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy='epoch' ,\n",
        "    disable_tqdm=False\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "HbsOibrZ1RNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conmputação de métricas"
      ],
      "metadata": {
        "id": "451DlGnk1ZhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computer_metrics(pred) :\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels,preds,average='weighted')\n",
        "    acc = accuracy_score(labels,preds)\n",
        "    return {\"acurracy : \" : acc , \"f1\" : f1}"
      ],
      "metadata": {
        "id": "m3X1xOuv1RPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento"
      ],
      "metadata": {
        "id": "ZTMnweNb1cH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model ,\n",
        "    args = training_args ,\n",
        "    compute_metrics = computer_metrics ,\n",
        "    train_dataset = dataset_tokenizado['train'] ,\n",
        "    eval_dataset= dataset_tokenizado['validation'] ,\n",
        "    tokenizer = tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "OGVzuAk11dil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "7EE8f0Pg1jAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliando modelo"
      ],
      "metadata": {
        "id": "JI1F6tTX1kkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ouptus = trainer.predict(\n",
        "    dataset_tokenizado['test']\n",
        ")\n",
        "pred_ouptus.metrics\n",
        ""
      ],
      "metadata": {
        "id": "TIlMItnF1mUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(\n",
        "    pred_ouptus.predictions,axis=1\n",
        ")\n",
        "y_true = dataset_tokenizer['test'][:]['label']"
      ],
      "metadata": {
        "id": "c6oIAPIl1mWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true,y_preds,output_dict=True))"
      ],
      "metadata": {
        "id": "M5-jkwQi1mYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "report_df = report_df.round(4)\n",
        "\n",
        "# Exibe a tabela\n",
        "print(report_df)"
      ],
      "metadata": {
        "id": "gClytfbV1mwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binariza os labels para ROC multiclasse\n",
        "y_test_bin = label_binarize(y_true, classes=list(range(len(classes))))\n",
        "\n",
        "# Calcula curva ROC e AUC para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plota as curvas ROC\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(len(classes)):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2,\n",
        "             label=f\"{classes[i]} (AUC = {roc_auc[i]:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
        "plt.ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
        "plt.title(\"Curva ROC por Classe\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qqZeY6s91sQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for i, cls in enumerate(classes):\n",
        "    # Protege contra índice fora do range se houver poucos thresholds\n",
        "    fpr_value = fpr[i][1] if len(fpr[i]) > 1 else fpr[i][0]\n",
        "    tpr_value = tpr[i][1] if len(tpr[i]) > 1 else tpr[i][0]\n",
        "\n",
        "    data.append({\n",
        "        \"Classe\": cls,\n",
        "        \"AUC\": round(roc_auc[i], 4),\n",
        "        \"FPR (Exemplo)\": round(fpr_value, 4),\n",
        "        \"TPR (Exemplo)\": round(tpr_value, 4)\n",
        "    })\n",
        "\n",
        "roc_df = pd.DataFrame(data)\n",
        "print(roc_df)"
      ],
      "metadata": {
        "id": "9VQBd-ff1tbM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoxNZew8mtLTccq1nEKbxl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palaceIA/CICS_Project/blob/main/src/notebooks/robert/robert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning RoBERTa Base Model\n",
        "Esse jupyter faz parte na nossa pesquisa para o Congresso Internacional (CICS) , aqui você ira encontrar nosso experimento referente ao modelo RoBERTa Base e os nossos devidos resultados. O dataset utlizado foi o \"dair-ai/emotion\" disponivel no HuggingFace"
      ],
      "metadata": {
        "id": "W9TzpcFawOmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RoBERTa-base\n",
        "RoBERTa é um modelo de transformadores pré-treinado em um grande corpus de dados em inglês de forma autossupervisionada. Isso significa que ele foi pré-treinado apenas nos textos brutos, sem humanos rotulando-os de forma alguma (é por isso que ele pode usar muitos dados disponíveis publicamente) com um processo automático para gerar entradas e rótulos desses textos.\n",
        "\n",
        "Mais precisamente, ele foi pré-treinado com o objetivo de modelagem de linguagem mascarada (MLM). Pegando uma frase, o modelo mascara aleatoriamente 15% das palavras na entrada e então executa a frase mascarada inteira através do modelo e tem que prever as palavras mascaradas. Isso é diferente das redes neurais recorrentes (RNNs) tradicionais que geralmente veem as palavras uma após a outra, ou de modelos autorregressivos como GPT que mascaram internamente os tokens futuros. Ele permite que o modelo aprenda uma representação bidirecional da frase.\n",
        "\n",
        "Dessa forma, o modelo aprende uma representação interna da língua inglesa que pode então ser usada para extrair características úteis para tarefas posteriores: se você tiver um conjunto de dados de frases rotuladas, por exemplo, poderá treinar um classificador padrão usando as características produzidas pelo modelo BERT como entradas.\n",
        "\n",
        "Note que este modelo tem como objetivo principal ser ajustado em tarefas que usam a frase inteira (potencialmente mascarada) para tomar decisões, como classificação de sequência, classificação de token ou resposta a perguntas. Para tarefas como geração de texto, você deve olhar para um modelo como GPT2."
      ],
      "metadata": {
        "id": "EN9-R3NxwzO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento do modelo\n",
        "\n",
        "O modelo RoBERTa foi pré-treinado na reunião de cinco conjuntos de dados:\n",
        "\n",
        "BookCorpus , um conjunto de dados composto por 11.038 livros não publicados;\n",
        "Wikipédia em inglês (excluindo listas, tabelas e cabeçalhos);\n",
        "CC-News , um conjunto de dados contendo 63 milhões de artigos de notícias em inglês rastreados entre setembro de 2016 e fevereiro de 2019.\n",
        "OpenWebText , uma recriação de código aberto do conjunto de dados WebText usado para treinar GPT-2,\n",
        "Histórias: um conjunto de dados contendo um subconjunto de dados do CommonCrawl filtrados para corresponder ao estilo de história dos esquemas do Winograd.\n",
        "Juntos, esses conjuntos de dados pesam 160 GB de texto."
      ],
      "metadata": {
        "id": "A5MxP4p-w920"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando os modulos\n",
        "!pip install torch transformers datasets matplotlib numpy scikit-learn pandas"
      ],
      "metadata": {
        "id": "GewI_C5VxIVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando os modulos"
      ],
      "metadata": {
        "id": "_1pozv9axKb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    AutoTokenizer,\n",
        "    AutoModel\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score ,\n",
        "    f1_score ,\n",
        "    classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "B5B_8Pg-xIar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o dataset"
      ],
      "metadata": {
        "id": "dI115_xqxRyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_data = \"dair-ai/emotion\"\n",
        "dataset = load_dataset(id_data)"
      ],
      "metadata": {
        "id": "9ondIeZmxIdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entendendo os dados"
      ],
      "metadata": {
        "id": "eZxcwdEwxXFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estrutura do dataset\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "5iDH3rBbxIf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de classes do dataset\n",
        "classes = dataset['train'].features['label'].names\n",
        "classes"
      ],
      "metadata": {
        "id": "3UTAypktxIil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alterando o formato do dataset para um tipo pandas\n",
        "dataset.set_format(type='pandas')\n",
        "df_pandas = dataset['train'][:]\n",
        "df_pandas.head()"
      ],
      "metadata": {
        "id": "3uyVqej0xb2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma tabela para cada classe correspondente\n",
        "df_pandas['label_name'] = df_pandas['label'].apply(lambda x : classes[x])\n",
        "df_pandas.head()"
      ],
      "metadata": {
        "id": "DFw6c2Vpxd2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o balanceamento das classes\n",
        "total_classes = df_pandas['label_name'].value_counts()\n",
        "total_classes"
      ],
      "metadata": {
        "id": "kQheBYsoxe-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resetando o formato original dos dados\n",
        "dataset.reset_format()"
      ],
      "metadata": {
        "id": "PxvHxvfJx1qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o tokenizador do modelo"
      ],
      "metadata": {
        "id": "5VXgi0qTx2No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_model = 'FacebookAI/roberta-base'\n",
        "tokenizador = AutoTokenizer.from_pretrained(id_model)"
      ],
      "metadata": {
        "id": "geflYjVAx4Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# passaremos a quantidade de batchs dos dados\n",
        "# Para aplicar essas a tokenizaço de todos os dados\n",
        "# basta usar o metodo map()\n",
        "# Função para tokenizar o dataset\n",
        "def tokenizador_lote(batch):\n",
        "    temp = tokenizador(\n",
        "        batch['text'],  # Aqui, 'batch' deve ser um dicionário com uma chave 'text'\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "    )\n",
        "    return temp"
      ],
      "metadata": {
        "id": "uMZv9Hvhx4b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizando os dados"
      ],
      "metadata": {
        "id": "Uba_sYVTyAiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_tokenizado = dataset.map(\n",
        "    tokenizador_lote,\n",
        "    batched = True ,\n",
        "    batch_size=None\n",
        ")"
      ],
      "metadata": {
        "id": "rul0JaP_x4dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando os modelo"
      ],
      "metadata": {
        "id": "sfP5kqFgyFSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= AutoModel.from_pretrained(id_model)"
      ],
      "metadata": {
        "id": "8bCcuGXHyH8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "RSVPhsW3yIxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurações iniciais para o ajuste fino"
      ],
      "metadata": {
        "id": "aVxtijZOyK7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Armazenando numero de classes\n",
        "numero_classes = len(classes)\n",
        "# Inicializando plataforma CUDA\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    id_model , num_labels = numero_classes\n",
        ")"
      ],
      "metadata": {
        "id": "980tBYILyPBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "Xa4Gz8xAyQC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurações do treinamento"
      ],
      "metadata": {
        "id": "eGnOneTGyR6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho do lote\n",
        "batch_size = 15\n",
        "model_name = 'roberta-base-emotions'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name ,\n",
        "    num_train_epochs=4 ,\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size= batch_size ,\n",
        "    per_device_eval_batch_size=batch_size ,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy='epoch' ,\n",
        "    disable_tqdm=False\n",
        ")"
      ],
      "metadata": {
        "id": "lEcJdQeXyUK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computação de métricas"
      ],
      "metadata": {
        "id": "4nPPbJ3Xylbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computer_metrics(pred) :\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels,preds,average='weighted')\n",
        "    acc = accuracy_score(labels,preds)\n",
        "    return {\"acurracy : \" : acc , \"f1\" : f1}\n",
        ""
      ],
      "metadata": {
        "id": "rdCDqrLdyoUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento"
      ],
      "metadata": {
        "id": "qtKVfiBoypoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model ,\n",
        "    args = training_args ,\n",
        "    compute_metrics = computer_metrics ,\n",
        "    train_dataset = dataset_tokenizado['train'] ,\n",
        "    eval_dataset= dataset_tokenizado['validation'] ,\n",
        "    tokenizer = tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "zj34vA3Pyqvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "6LOYhGjDyqxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliando modelo"
      ],
      "metadata": {
        "id": "LjGnKU26yv73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(\n",
        "    pred_ouptus.predictions,axis=1\n",
        ")\n",
        "y_true = dataset_tokenizer['test'][:]['label']"
      ],
      "metadata": {
        "id": "hXC6IY1_yyEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true,y_preds,output_dict=True))"
      ],
      "metadata": {
        "id": "iwYYotGFyyGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_df = pd.DataFrame(report_dict).transpose()\n",
        "report_df = report_df.round(4)\n",
        "\n",
        "# Exibe a tabela\n",
        "print(report_df)"
      ],
      "metadata": {
        "id": "IQA_jvOvyyJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binariza os labels para ROC multiclasse\n",
        "y_test_bin = label_binarize(y_true, classes=list(range(len(classes))))\n",
        "\n",
        "# Calcula curva ROC e AUC para cada classe\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(len(classes)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plota as curvas ROC\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(len(classes)):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2,\n",
        "             label=f\"{classes[i]} (AUC = {roc_auc[i]:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
        "plt.ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
        "plt.title(\"Curva ROC por Classe\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "75k4cEaoyyOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for i, cls in enumerate(classes):\n",
        "    # Protege contra índice fora do range se houver poucos thresholds\n",
        "    fpr_value = fpr[i][1] if len(fpr[i]) > 1 else fpr[i][0]\n",
        "    tpr_value = tpr[i][1] if len(tpr[i]) > 1 else tpr[i][0]\n",
        "\n",
        "    data.append({\n",
        "        \"Classe\": cls,\n",
        "        \"AUC\": round(roc_auc[i], 4),\n",
        "        \"FPR (Exemplo)\": round(fpr_value, 4),\n",
        "        \"TPR (Exemplo)\": round(tpr_value, 4)\n",
        "    })\n",
        "\n",
        "roc_df = pd.DataFrame(data)\n",
        "print(roc_df)"
      ],
      "metadata": {
        "id": "CqUAAkFiyyQ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}